\documentclass[notheorems, handout]{beamer}


\usetheme[numbers,totalnumbers,compress, nologo]{Statmod}
\usefonttheme[onlymath]{serif}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{theorems}[numbered]
\setbeamertemplate{caption}[numbered]

\mode<handout> {
	\usepackage{pgfpages}
	\setbeameroption{show notes}
	% \pgfpagesuselayout{2 on 1}[a4paper, border shrink=5mm]
	\setbeamercolor{note page}{bg=white}
	\setbeamercolor{note title}{bg=gray!10}
	\setbeamercolor{note date}{fg=gray!10}
}

% убирает заметки
\setbeameroption{hide notes}

\usepackage[utf8x]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage[russian]{babel}
\usepackage{tikz}
\usepackage{ragged2e}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{color}
\usepackage{dcolumn}
\usepackage{bm}
\usepackage{float}
\usepackage[authoryear]{natbib}
%\usepackage[numbers, sort&compress]{natbib}


\newtheorem{corollary}{Следствие}
\newtheorem{theorem}{Теорема}
\newtheorem{remark}{Замечание}
\newtheorem{comment}{Замечание} % задаём выводимое слово (для определений)
\newtheorem{lemma}{Лемма}
\newtheorem{sentence}{Предложение}
\newtheorem{definition}{Определение}
\newtheorem{formulation}{Формулировка}
\newtheorem{statement}{Постановка}
\DeclareMathOperator{\R}{\mathbb{R}}
\DeclareMathOperator{\rank}{\mathrm{rank}}
\newcommand{\norm}[1]{\left\|#1\right\|}

\newcommand{\SSA}{\textbf{SSA}}
\newcommand{\GSSA}{\textbf{GSSA}}
\newcommand{\CISSA}{\textbf{CiSSA}}
\newcommand{\TS}{\mathsf{X}}



\title[Модификации метода $\SSA$]{Модификации метода анализа сингулярного спектра для анализа временных рядов: Circulant SSA и Generalized SSA }

\author{Погребников Николай Вадимович, гр. 21.Б04-мм}

\institute[Санкт-Петербургский Государственный Университет]{%
	\small
	Санкт-Петербургский государственный университет\\
	Прикладная математика и информатика\\
	Вычислительная стохастика и статистические модели\\
	\vspace{1cm}
%	4 курс (бак.) <<Производственная практика (научно-исследовательская работа)>>\\(Семестр 6)
	Научный руководитель:  д.\,ф.-м.\,н., доц. Голяндина Н.Э.
}
	

\date[Зачет]{Санкт-Петербург, 2025}

\subject{Talks}

\begin{document}

	\begin{frame}[plain]
		\titlepage
		
		\note{Научный руководитель  д.\,ф.-м.\,н., доц. Голяндина Нина Эдуардовна,\\
			кафедра статистического моделирования}
	\end{frame}
	
	%\section{Короткая тема}
	%\subsection{Общие слова}
	
%	\setbeameroption{show notes}
	
	\begin{frame}{Введение}
		Временные ряды представляют собой последовательность данных, собранных или
		измеренных в хронологическом порядке. Понимание эволюции явлений во времени является критическим для выявления тенденций, циклов и аномалий. В этих целях были созданы методы разложения временных рядов на сумму интерпретируемых компонент такие как $\SSA$ \citep{golyandina2001analysis} и его модификации: $\GSSA$ \cite{gu2024generalized},  $\CISSA$ \citep{bogalo2020}.
		 \newline \newline
		Целью работы является описание модификаций в контексте теории $\SSA$ и на этой основе сравнение методов по теоретическим свойствам и численно.
		%		Задача --- оценка ошибок восстановления ряда.
		%		Тут какое-то введение.
		%		Что за задача решается, какое метод используется, какая цель работы.
		
		\note{
			Сингулярный спектральный анализ ($\SSA$ \citep{golyandina2001analysis}) --- метод, целью которого является разложение оригинального ряда на сумму небольшого числа интерпретируемых компонент, таких как медленно изменяющаяся тенденция (тренд), колебательные компоненты (сезонность) и ``структурный'' шум.  В данном исследовании
			рассматривается математическая составляющая вариации алгоритма $\SSA$ --- circulant singular spectrum analysis ($\CISSA$), предложенная в статье \citep{bogalo2020}, а также сравнение базового метода и циркулярного, применение их на языке R.
		}
	\end{frame}
	
	
	
	\begin{frame}{Метод SSA. Алгоритм: разложение}
		Для временного ряда $\TS = (x_1, \dots, x_{N})$ выбирается длина окна $L$, $1 < L < N$ и определяется $K = N - L + 1$. Строится L-траекторная матрица $\mathbf{X}$, состоящая из столбцов вида $\TS_i = ( x_{i-1}, \ldots, x_{i+L-2})^{\mathrm{T}}$,
		$1 \leq i \leq K$. \\
		
		
		Пусть $\mathbf{S} = \mathbf{X}\mathbf{X}^{\mathrm{T}}$, 
		$\lambda_1, \dots, \lambda_L$ --- собственные числа матрицы $\mathbf{S}$, взятые в неубывающем порядке. \\
		\begin{definition}
			Сингулярным разложением называется представление матрицы в виде:
			\begin{equation}
				\mathbf{X} = \mathbf{X}_1 + \dots + \mathbf{X}_d =
				\sum_{i = 1}^{d} \sqrt{\lambda_i} U_i V_{i}^{\mathrm{T}}\label{eq:u},
				\text{где}
			\end{equation}
			
			$U_1, \dots, U_L$ --- ортонормированная система собственных векторов матрицы $\mathbf{S}$, $d = \max{ \{i: \lambda_i > 0 \}}$ и 
			$V_i = \mathbf{X}^{\mathrm{T}} U_i / \sqrt{\lambda_i}$.
		\end{definition}
		
		Набор $( \sqrt{\lambda_i}, U_i, V_{i}^{\mathrm{T}})$ называется $i$-й собственной тройкой.
		
		\note{
			Полезным свойством является то, что матрица $\mathbf{X}$ имеет одинаковые элементы на антидиагоналях. Таким образом, $L$-траекторная матрица является ганкелевой.
			
			Набор $( \sqrt{\lambda_i}, U_i, V_{i}^{\mathrm{T}})$ называется $i$-й собственной тройкой разложения $\mathbf{X}$.
		}
	\end{frame}


	\begin{frame}{Метод SSA. Алгоритм: восстановление}
		На основе разложения \eqref{eq:u} производится процедура группировки, которая делит все множество индексов $\{1, \dots, d\}$ на $m$ непересекающихся подмножеств $I_1, \dots, I_d$. \\
		Пусть $I = \{i_1, \dots, i_p\}$, тогда $\mathbf{X}_I =
		\mathbf{X}_{i_1} + \dots + \mathbf{X}_{i_p}$. Такие матрицы вычисляются для каждого $I = I_1, \dots, I_m$. \newline \newline \pause
		В результате получаются матрицы $\mathbf{X}_{I_1}, \dots, \mathbf{X}_{I_m}$, для каждой из которых проводится операция диагонального усреднения, составляющая ряды длины $N$: $\TS_1, \dots, \TS_m$. \\ 
		При этом, $\TS_1 + \dots + \TS_m = \TS$.
		
		\note{
			Диагональное усреднение для каждой антидиагонали усредняет значения элементов матрицы.
			
			Применяя данную операцию к матрицам $\mathbf{X_{I_1}}, \dots, \mathbf{X_{I_m}}$, получаются $m$ новых рядов: $\TS_1, \dots, \TS_m$. При этом, $\TS_1 + \dots + \TS_m = \TS$.
		}
		
		
	\end{frame}
	
	
	\begin{frame}{Метод GSSA. Алгоритм}
		Алгоритм $\GSSA$ сильно схож с базовым $\SSA$. Пусть $N > 2$, вещественнозначный временной ряд
		$\TS = (x_1, \dots, x_{N})$ длины $N$. Фиксируется параметр $\alpha \geq 0$, отвечающий за веса:
		\begin{equation*}
			{\boldsymbol{w}}^{(a)} = (w_{1}, w_{2}, \ldots, w_{L}) = \left( \left| \sin\left(\frac{\pi n}{L+1}\right) \right| \right)^\alpha, \quad n = 1, 2, \dots, L.
		\end{equation*}
		Для временного ряда $\TS = (x_1, \dots, x_{N})$ выбирается длина окна $L$, $1 < L < N$ и определяется $K = N - L + 1$. Строится L-траекторная матрица $\mathbf{X}^{(\alpha)}$, состоящая из столбцов вида $\TS_i^{(\alpha)} = ( w_1 x_{i-1}, \ldots, w_L x_{i+L-2})^{\mathrm{T}}$,
		$1 \leq i \leq K$. 
		\newline \newline
		Остальные действия те же самые, что и в $\SSA$.
		
		\begin{comment}
			При $\alpha = 0$, $\GSSA$ --- в точности базовый алгоритм $\SSA$.
		\end{comment}
	\end{frame}
	
	
	\begin{frame}{Сравнение SSA и GSSA. Линейные фильтры 1}
		\begin{definition}
			Пусть бесконечный временной ряд $\TS = (\dots, x_{-1}, x_0, x_1, \dots)$. Линейный конечный фильтр --- это оператор $\Phi$, который преобразует временной ряд $\TS$ в новый по следующему правилу:
			\begin{equation*}
				y_j = \sum \limits_{i = -r_1}^{r_2} h_i x_{j-i}; \quad r_1, r_2 < \infty.
			\end{equation*}
		\end{definition} 
		Связанные определения:
		\begin{itemize}
			\item ${h_i}$ --- импульсная характеристика фильтра;
			\item 		$H_{\Phi}(z) = \sum \limits_{i = -r_1}^{r_2} h_i z^{-i}$ --- передаточная функция;
			\item $A_{\Phi}(\omega) = \left| H_{\Phi}\left(e^{i2\pi\omega}\right) \right|$ --- АЧХ;
			\item $\phi_{\Phi}(\omega) = \operatorname{Arg}\left(H_{\Phi}\left(e^{i2\pi\omega}\right)\right)$ --- ФЧХ.
		\end{itemize}
		\textbf{\large{Пример.}} При применении фильтра $\Phi$ на $\TS_{\cos} = \cos{2\pi \omega n}$, получается ряд
		$y_j = A_{\Phi}(\omega) \cos\left(2\pi\omega j + \phi_{\Phi}(\omega) \right)$.
	\end{frame}
	
	
	\begin{frame}{Сравнение SSA и GSSA. Линейные фильтры 2}
		Пусть $\TS = (x_1, \dots, x_{N})$ --- временной ряд длины $N$, $(\sqrt{\lambda},\,U,\,V)$ — одна из собственных троек разложения методом $\SSA$. $U = (u_1, \dots, u_L)$.
		
		Тогда компонента временного ряда $\widetilde \TS$, восстановленная с использованием собственной тройки $(\sqrt{\lambda},\,U,\,V)$, для средних точек (индексы от $L$ до $K$) имеет вид:
		\begin{equation*}
			\label{eq:representation_ssa_as_filter}
			{\widetilde{x}}_{s} = \sum_{j=-(L-1)}^{L-1} \left( \sum_{k=1}^{L-|j|} u_{k} u_{k+|j|} / L \right) x_{s-j}, \quad L \leq s \leq K.
		\end{equation*}
		Таким образом, имеется представление алгоритма $\SSA$ через линейные фильтры.
		
		Аналогичное представления для $\GSSA$:
		\begin{equation*}
			\label{eq:representation_gssa_as_filter}
			{\widetilde{x}}_{s} = \sum_{j=-(L-1)}^{L-1} \left( \sum_{k=1}^{L-|j|} u_{k}^{(\alpha)} u_{k+|j|}^{(\alpha)} w_k / \sum\limits_{i = 1}^{L}w_i \right) x_{s-j}, \quad L \leq s \leq K.
		\end{equation*}
	\end{frame}
	
	\begin{frame}{Сравнение SSA и GSSA. Пример}
		$\TS = \TS_{\sin} + \TS_{\cos} = \sin\left(\frac{2\pi}{12} n \right) + \frac{1}{2}\cos\left(\frac{2\pi}{19} n \right)$. $N = 96 \cdot 2 - 1$, $L = 48$.
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.8\textwidth]{../Text/img/various_alphas_sin_cos.png}
			\caption{Ряд $\TS = \TS_{\sin} + \TS_{\cos}$. АЧХ фильтров, отвечающих за $\TS_{\sin} = \sin\left(\frac{2\pi}{12} n \right)$, при разных $\alpha$}
			\label{fig:various_alphas_sin_cos}
		\end{figure}
	\end{frame}
	
	
	\begin{frame}{Сравнение SSA и GSSA. Пример, продолжение}
		\begin{table}[H]
			\centering
			\begin{tabular}{c|ccc}
				\hline
				Метод/Ошибка & $\TS_{\sin}$ & $\TS_{\cos}$ & $\TS$ \\ 
				\hline
				SSA   & 5.15e-03 & 5.15e-03 & 6.01e-30\\ 
				GSSA, $\alpha = \frac{1}{2}$  & 3.68e-04 & 3.68e-04 & 9.53e-30 \\ 
				\hline
			\end{tabular}
			\caption{MSE разложений ряда $\TS = \TS_{\sin} + \TS_{\cos}$ для $\SSA$ и $\GSSA$ с $\alpha = \frac{1}{2}$}
			\label{tab:mse_ssa_gssa}
		\end{table}
		Добавим к $\TS$ шумовую компоненту: $\TS = \TS_{\sin} + \TS_{\cos} + \TS_{\mathrm{noise}} =
		\sin\left(\frac{2\pi}{12}x\right) +
		\frac{1}{2}\cos\left(\frac{2\pi}{19}x\right)+
		\varepsilon_n$, 
		где $\varepsilon_n \sim \mathrm N(0, 0.1^2)$.
		\begin{table}[H]
			\centering
			\begin{tabular}{c|ccc}
				\hline
				Метод & $\TS_{\sin}$ & $\TS_{\cos}$ & $\TS$ \\ 
				\hline
				SSA      & 5.68e-03 & 5.44e-03 & 7.48e-04  \\ 
				GSSA, $\alpha = \frac{1}{2}$ & 1.21e-03 & 1.25e-03 & 1.04e-03 \\
				\hline
			\end{tabular}
			\caption{MSE разложений ряда $\TS = \TS_{\sin} + \TS_{\cos} + \TS_{\mathrm{noise}}$ для $\SSA$ и $\GSSA$ с $\alpha = \frac{1}{2}$}
			\label{tab:errs_ssa_gssa}
		\end{table}
	\end{frame}
	
	
	
	\begin{frame}{Сравнение SSA и GSSA. Выводы}
		По теоретическим результатам и примерам можно сделать понять, что $\GSSA$ позволяет улучшить разделимость периодических компонент ряда. Однако, вместе с тем, разложение будет захватывать больше шума в сравнении с базовым $\SSA$.
	\end{frame}
	
	
%	\begin{frame}{Метод SSA. Свойства: точная разделимость}
%		Пусть временной ряд  $\TS = \TS^{(1)} + \TS^{(2)}$ и задачей является нахождение этих слагаемых.
%		
%		Будем говорить, что ряд $\TS$ точно разделим на $\TS^{(1)} $ и $ \TS^{(2)}$, если существует такое сингулярное разложение траекторной матрицы $\mathbf X$ ряда $\TS$, что его можно разбить на две части, являющиеся сингулярными разложениями траекторных матриц рядов $\TS^{(1)}, \TS^{(2)}$ \citep{golyandina2001analysis}.
%		
%		
%		
%		
%		\note{
%			Условия точной разделимости выводятся из понятий слабо L-разделимых рядов и сильно L-разделимых рядов \citep{golyandina2001analysis}. Стоит отметить, что точная разделимость для $\cos$ достигается, если $Lw \in \mathbb{N}, \, Kw \in \mathbb{N}$, где $w$ --- частота.
%			
%			Однако условия точной разделимости достаточно жесткие и вряд ли выполнимы в реальных задачах. Тогда появляется такое понятие, как асимптотическая разделимость.
%		}
%		
%		
%	\end{frame}
%	
	
	
%	\begin{frame}{Метод SSA. Свойства: асимптотическая разделимость}
%		
%		\begin{equation*}
%			\rho_{i,j}^{(M)}=\frac{\left(\TS_{i,i+M-1}^{(1)},\TS_{j,j+M-1}^{(2)}\right)}{\left|\left|\TS_{i,i+M-1}^{(1)}\right|\right|\left|\left|\TS_{j,j+M-1}^{(2)}\right|\right|}.
%		\end{equation*}
%		
%		\begin{definition}
%			Ряды $\TS^{(1)}, \TS^{(2)}$ называются $\varepsilon$-разделимыми при длине окна $L$, если
%			\begin{equation*}
%				\rho^{(L,K)}\ {\stackrel{\mathrm{def}}{=}}\ \mathrm{max}\left(\operatorname*{max}_{1\leq i,j\leq K}|\rho_{i,j}^{(L)}|,\operatorname*{max}_{1\leq i,j\leq L}|\rho_{i,j}^{(K)}|\right)<\varepsilon
%				\text{  .}
%			\end{equation*}
%			
%		\end{definition}
%		
%		\begin{definition}
%			Если $\rho^{(L(N),K(N))} \rightarrow 0$ при некоторой последовательности $L = L(N) $, $N \rightarrow \infty$, то ряды $\TS^{(1)}, \TS^{(2)}$ называются асимтпотически $L(N)$-разделимыми \citep{golyandina2001analysis}.
%		\end{definition}
%		
%		\note{
%			Для любого ряда $\TS$ длины $N$ определим
%			$\TS_{i,j}\,=\,(x_{i-1},\cdot\cdot\cdot,x_{j-1}),\;\;1\,\leq\,i\,\leq\,j\,<\,N.$
%			Пусть $\TS^{(1)}=(x_{0}^{(1)},\ldots,x_{N-1}^{(1)}),\TS^{(2)}=(x_{0}^{(2)},\ldots,x_{N-1}^{(2)}).$ Тогда определим коэффициент корреляции.
%			
%		}
		
		
%	\end{frame}
	
	
%	\begin{frame}{Метод SSA. Свойства: асимптотическая разделимость}
%		
%		
%		
%		\begin{comment}
%			Для $\SSA$ существуют алгоритмы улучшения разделимости \citep{golyandina2023intelligent}. Они позволяют более точно отделять временные ряды друг от друга. В данной работе будут использоваться методы EOSSA и FOSSA.
%		\end{comment}
%		
%		\note{
%			Для нас важно, что благодаря применению улучшения разделимости мы можем делать автоматическую группировку по заданным частотам в базовом алгоритме $\SSA$.
%		}
%		
%		
%	\end{frame}
	
	
	
	\begin{frame}{Метод CiSSA. Алгоритм: разложение}
		Как и в $\SSA$ считается $\mathbf X$, по которой строится $\hat{\mathrm{C}}_{L}$:
		$\hat c_m = \frac{L-m}{L}\hat{\gamma}_m + \frac{m}{L}\hat{\gamma}_{L-m}$, $ \hat{\gamma}_m = \frac{1}{N-m} \sum \limits_{t = 1}^{N-m}x_t x_{t+m}$, $ \, m = 0:L-1$.
		\begin{equation*}
			\label{eq:circ_mat}
			\hat{\mathrm{C}}_{L}=\left(\begin{array}{cccc}
				\hat c_{1} & \hat c_{2} & \ldots & \hat c_{L} \\
				\hat c_{2} & \hat c_{1} & \ldots & \hat c_{L-1} \\
				\vdots & \vdots & \vdots & \vdots \\
				\hat c_{L} & \hat c_{L-1} & \hdots & \hat c_{1}
			\end{array}\right).
		\end{equation*}
		Собственные числа и вектора матрицы $\hat{\mathrm{C}}_{L}$, задаются по формулам:
		\begin{equation*}
			\begin{split}
				&U_{k}=L^{-1/2}(u_{k,1\cdot}\cdot\cdot\cdot,u_{k,L}), \, \text{где} \, 
				u_{k,j}=\exp\left(-\mathrm{i}2\pi\d(j-1)\frac{k-1}{L}\right), \\
				&\lambda_{L,k}=\sum_{m=0}^{L-1}\hat c_{m}\exp\left(i 2\pi m\frac{k-1}{L}\right), \, k = 1:L.
			\end{split}
		\end{equation*}
		
		\note{
			Модификация $\SSA$ на основе циркулярной матрицы \citep{bogalo2020}. Авторы метода называют её автоматизированной. Причем автоматизированная в том смысле, что компоненты ряда группируются по частотам самим алгоритмом.
		}
		
	\end{frame}
	
	
	
	\begin{frame}{Метод CiSSA. Алгоритм: восстановление}
		Для каждой частоты $w_k = \frac{k-1}{L}$, $k = 2:\lfloor \frac{L+1}{2} \rfloor$, есть два собственных вектора: $U_k$ и $U_{L+2-k}$. За частоту $w_1$ отвечает один собственный вектор --- $U_1$. Если $L$ --- четное, то частоте $w_{\frac{L}{2} + 1}$ будет соответствовать один вектор $U_{\frac{L}{2}+1}$.
		
		Следовательно, индексы разбиваются на элементарную группировку следующим образом:
		\begin{equation*}
			\begin{split}
				&B_1 = \{1\}; \, B_k = \{k, L+2-k\}, \,  \text{для } k = 2:\lfloor \frac{L+1}{2}\rfloor; \\ \, 
				&B_{\frac{L}{2} + 1} = \left\{ \frac{L}{2} + 1 \right\}, \, \text{если} \, L \mid  2.
			\end{split}
		\end{equation*}
		$\mathbf X_{B_k} = \mathbf X_k + \mathbf X_{L+2-k} = U_k U_k^H \mathbf X + U_{L+2-k} U_{L+2-k}^H \mathbf X$, \\где $U^H$ --- это комплексное сопряжение и транспонирование вектора $U$. Далее идет группировка по диапазонам интересующих частот, после чего следует диагональное усреднение.
		
		\note{
			Группировка будет производиться на непересекающиеся подгруппы по частотам от $0$ до $0.5$, поскольку частоты выше 0.5 представляют собой зеркальное отражение частот ниже 0.5. Именно поэтому объединяются матрицы $\mathbf X_{B_k} = \mathbf X_k + \mathbf X_{L+2-k}$.
		}
		
	\end{frame}
	
	
	
	\begin{frame}{Метод CiSSA. Свойства: связь с разложением Фурье}
		\begin{definition}
			Разложение
			\begin{equation}
				\label{eq:fourier}
				x_n = c_0 + \sum\limits_{k = 1}^{\lfloor \frac{N+1}{2} \rfloor}\left(c_k \cos(2\pi n k / N) + s_k \sin(2\pi n k / N) \right),
			\end{equation}
			где $1 \leq n \leq N$ и $s_{N/2} = 0 $ для четного N, называется разложением Фурье ряда $\TS$. 
		\end{definition}
		\begin{comment}
			\label{comm:proector}
			$U_k U_k^H + U_{L+2-k} U_{L+2-k}^H$ является оператором проектирования на подпространство, которое порождено синусами и косинусами с частотой $w_k = \frac{k-1}{L}$. То есть, воспроизводится разложение Фурье для $K$ векторов матрицы $\mathrm X$. Затем вычисляется диагональное усреднение.
		\end{comment}
		\note{
			По замечанию \ref{comm:proector} видно, что при вычислении $\mathbf X_{B_k} = \mathbf X_k + \mathbf X_{L+2-k} = U_k U_k^H \mathbf X + U_{L+2-k} U_{L+2-k}^H \mathbf X$, воспроизводится разложение Фурье для $K$ векторов матрицы $\mathrm X$. Затем вычисляется диагональное усреднение $\mathbf *X_{B_k}$.
		}
		
	\end{frame}
	
%	\begin{frame}{Метод CiSSA. Свойства: разделимость}
%		\textbf{Точная разделимость.}
%		Поскольку данный метод является аналогом разложения Фурье, то в смысле сильной разделимости можно точно разделить ряд, в котором одной из компонентов является $\cos(2\pi w + \varphi)$ с частотой $w$ такой, что $Lw = k \in \mathbb N$, или константа.
%		
%		\textbf{Асимптотическая разделимость.} 
%		\begin{definition}
%			Пусть $\TS = \TS^{(1)} + \TS^{(2)}$. Существуют такие диапазоны частот $I_1$ и $I_2$ и последовательность $L = L(N) $, $N \rightarrow \infty$, что при них $\mathrm{MSE}\left(\TS^{(1)}, \TS^{(1)}_{\CISSA}\right) \rightarrow 0$ и $\mathrm{MSE}\left(\TS^{(2)}, \TS^{(2)}_{\CISSA}\right) \rightarrow 0$, где $MSE$ --- среднеквадратическая ошибка, $\TS^{(1)}_{\CISSA}$ и $ \TS^{(2)}_{\CISSA}$ компоненты ряда, полученные алгоритмом $\CISSA$ для частот $I_1$ и $I_2$, то ряды $\TS^{(1)}$ и $ \TS^{(2)}$ называются $\CISSA$-асимтпотически $L(N)$-разделимыми.
%		\end{definition}
%		
%		\note{
%			Асимптотическая разделимость в данном случае будет означать, что при увеличении $L$ разбиение сетки будет увеличиваться, а значит, и частоты в сетке начнут сближаться к истинным частотам периодических компонентов (либо становиться равными им), что будет снижать ошибку вычислений.
%		}
%		
%	\end{frame}
	
	
%	\begin{frame}{Метод CiSSA. Свойства: эквивалентность методов}
%		\begin{definition}
%			Будем говорить, что методы $M_1$ и $M_2$ асимптотически эквивалентны, если их матрицы вложения $S_1$, $S_2$ асимптотически эквиваленты в смысле $\operatorname*{lim}\limits_{L\rightarrow\infty \, N\rightarrow\infty}\frac{||{S_1-S_2}||_F}{\sqrt{L}}=0$, при некоторой последовательности $L = L(N) $, $N \rightarrow \infty$, где $||{\cdot}||_F$ --- норма Фробениуса. Тогда $M_1 \sim M_2$, $S_1 \sim S_2$.
%		\end{definition}
%		
%		
%		\begin{theorem}
%			\label{th:equiv}
%			Пусть $\TS$ --- стационарный временной ряд.
%			Дана $L \times K$ траекторная матрица $\mathbf{X}$. Пусть $S_B = \mathbf{X} \mathbf{X}^T / K$, $S_C$ --- матрица, определенная в \eqref{eq:circ_mat}. Тогда $S_B \sim S_C$.
%		\end{theorem}
%		\begin{proof}
%			Доказательство в источнике \citep{bogalo2020}.
%		\end{proof}
%		
%		\note{
%			В статье \citep{bogalo2020} говорится, что асимптотически методы $\SSA$ и $\CISSA$ эквивалентны и в доказательство приводится теорема.
%		}
%		
%	\end{frame}
	
	\begin{frame}{Метод CiSSA. Свойства: нестационарный ряд}
		Для использования на нестационарных временных рядах, нужно выполнить расширения ряда (экстраполировать) \citep{bogalo2020}.
		
		\begin{figure}[H]
			\centering
			\includegraphics[width=0.75\textwidth]{../Text/img/extended_IP_values.png}
			\caption{Красный --- настоящий ряд, черный --- расширеннный}
			\label{fig:extended_IP_values}
		\end{figure}
		
		Так, алгоритм лучше выделяет нелинейную составляющую.
		
		\note{
			Формальное определение стационарности ряда можно увидеть в отчёте данной работы \citep{spbu_cissa_coursework_github}. Стационарный ряд --- это такой временной ряд, в котором изменения происходят вокруг некоторого среднего значения, и это среднее остаётся более-менее постоянным на протяжении всего ряда.
			
			Сама процедура расширения ряда $\TS$ производится с использованием авторегрессионной (AR) модели.
		}
		
		
	\end{frame}
	
	
	\begin{frame}{Сравнение SSA, Фурье, CiSSA. Разделимость}
		\begin{definition}
			\label{def:exact}
			Есть метод разделения ряда на компоненты с параметрами \( \Theta \), ряд \( \TS = \TS^{(1)} + \TS^{(2)} \). $\exists$ набор параметров \( \hat{\Theta} \), \( L \), \( N\), что при разделении ряда на компоненты этим методом, \( \hat{\TS}^{(1)} \) является оценкой \( \TS^{(1)} \), при этом, \( \mathrm{MSE}\left(\TS^{(1)}, \hat{\TS}^{(1)}\right) = 0 \). Тогда ряды \( \TS^{(1)} \) и \( \TS^{(2)} \) точно разделимы данным методом.
		\end{definition}
		\begin{definition}
			\label{def:asymp}
			Есть метод разделения ряда на компоненты с параметрами \( \Theta \), ряд \( \TS = \TS^{(1)} + \TS^{(2)} \). $\exists$ набор параметров \( \hat{\Theta} \) и \( L = L(N) \), \( N \rightarrow \infty \), что при разделении ряда на компоненты этим методом, \( \hat{\TS}^{(1)} \) является оценкой \( \TS^{(1)} \), при этом, \( \mathrm{MSE}\left(\TS^{(1)}, \hat{\TS}^{(1)}\right) \rightarrow 0 \). Тогда ряды \( \TS^{(1)} \) и \( \TS^{(2)} \) называются асимптотически \( L(N) \)-разделимыми данным методом.
		\end{definition}
	\end{frame}
	
	
	
	\begin{frame}{Сравнение SSA, Фурье, CiSSA. Точная разделимость}
		Фиксируем временной ряд $\TS = \TS_{1} + \TS_{2} =$ $= A_1 \exp(\alpha_1 n)\cos(2\pi w_1 n + \varphi_1) + A_2 \exp(\alpha_2 n)\cos(2\pi w_2 n + \varphi_2)$.
		\newline \newline
		Условия точной разделимости $\TS$ для разложения Фурье: \\
		$Nw_1, Nw_2 \in \mathbb{N}$, $w_1 \not = w_2$, $\alpha_1  = \alpha_2 = 0$.
		
		Условия точной разделимости $\TS$ для $\CISSA$: \\
		$Lw_1, Lw_2 \in \mathbb{N}$, $w_1 \not = w_2$, $\alpha_1 = \alpha_2 = 0$.
		
		Условия точной разделимости $\TS$ для $\SSA$: \\
		$Lw_1, Lw_2, Kw_1, Kw_2 \in \mathbb{N}$, $w_1 \not = w_2$, $A_1 \not = A_2$, $\alpha_1 \not = \alpha_2$.
		\newline \newline
		Таким образом, условия на разделение косинусов, слабее у методов $\CISSA$ и Фурье, чем у $\SSA$. Однако $\SSA$ может точно отличать друг от друга больше классов функций.
	\end{frame}
	
	
	\begin{frame}{Сравнение SSA, Фурье, CiSSA. Асимптотическая разделимость}
		Асимптотически разделимы в методе $\SSA$ полиномы, гармонические функции, не удовлетворяющие условиям точной разделимости, экспоненты \cite{golyandina2001analysis}.
		\begin{comment}
			Для $\SSA$ существуют алгоритмы улучшения разделимости, например, EOSSA и FOSSA \cite{golyandina2023intelligent}. По заданному набору компонент, они позволяют более точно отделять компоненты.
		\end{comment}
		В алгоритме разложения $\CISSA$ (Фурье) увеличение длины окна $L$ ($N$) изменяет сетку частот. Это означает, что даже если не удастся подобрать такое $L$ ($N$), при котором косинус будет точно отделим, его постепенное увеличение позволит приблизить частоты сетки к частоте компоненты. В итоге, можно снизить ошибку выделения нужной компоненты, учитывая соседние частоты.
	\end{frame}
	
	
	
	
	\begin{frame}{Сравнение SSA, Фурье, CiSSA. Выделение тренда}
		Любая непериодическая компонента будет отвечать частотам, близким к нулю. Из-за этого алгоритмы $\CISSA$ и разложение Фурье не смогут отличить друг от друга две непериодики.
		\newline \newline
		\textbf{\large{Пример.}} Рассмотрим ряд $\TS = \TS_{c} + \TS_e + \TS_{\sin} + \TS_{\cos} = 1 + e^{\frac{x}{100}} + \sin{\frac{2\pi}{12}x} + \frac{1}{2}\cos{\frac{2\pi}{3}x}$.
%		[width=0.75\textwidth]
		\begin{table}[H]
			\centering
			\resizebox{0.95\textwidth}{!}{ % Масштабируем таблицу
				\begin{tabular}{l|l|cccc}
					\hline
					Метод & Параметры & $\operatorname{MSE}(\TS_{c} + \TS_e)$ & $\operatorname{MSE}(\TS_{\sin})$ & $\operatorname{MSE}(\TS_{\cos})$ & $\operatorname{MSE}(\TS)$\\ 
					\hline
					SSA & $L = 96, K = 96$ & 5.0e-03 & 8.9e-07 & 5.2e-05 & 4.4e-03 \\ 
					SSA EOSSA, $r = 7$ & $L = 96, K = 96$ & 1.7e-28 & 1.6e-29 & 8.7e-30 & 1.6e-28 \\ 
					Fourier & $N = 96 \cdot 2$ & 1.1e-01 & 6.1e-04 & 6.8e-03 & 1.1e-01 \\ 
					Fourier extended & $N = 96 \cdot 2$ & 1.4e-03 & 1.3e-03 & 8.4e-03 & 9.6e-03 \\ 
					CiSSA & $L = 96$ & 5.3e-02 & 1.6e-05 & 4.9e-04 & 4.4e-02 \\ 
					CiSSA extended & $L = 96$ & 5.0e-04 & 2.1e-04 & 1.1e-03 & 6.0e-04 \\ 
					\hline
				\end{tabular}
			}
			\caption{MSE разложений ряда $\TS = \TS_{c} + \TS_e + \TS_{\sin} + \TS_{\cos}$} 
			\label{tab:errs_fourier_cissa_trend}
		\end{table}
		По таблице \ref{tab:errs_fourier_cissa_trend} видно, что расширение ряда негативно повлияло на выделение периодики и положительно на трендовую составляющую (непериодику).
		
	\end{frame}
	
	
	
	
	\begin{frame}{Сравнение SSA, Фурье, CiSSA. Выводы 1}
		
		\begin{table}[H]
			\centering
			\begin{center}
				\resizebox{0.95\textwidth}{!}{ % Масштабируем таблицу
				\begin{tabular}{l|cccccccc}
					\hline
					Метод/Условие  & $\cos$,                 & $\cos$,                    & $\cos$,                     & $\TS_{\mathrm{np1}}$   & $\TS_{\mathrm{np}}$ & group\\ 
					& $Lw \in \mathbb N$, & $Lw\in \mathbb N$,    & $Lw \not\in \mathbb N$, &             \\
					& $Kw\in \mathbb N$  & $Kw \not\in \mathbb N$ & $Kw \not\in \mathbb N$  &             \\ 
					\hline
					SSA            & $+$                     & $\to$                      & $\to$                       & $\to$ & $\to$ & $-$ \\
					SSA EOSSA      & $+$                     & $\to$                      & $\to$                       & $\to$ & $\to$ & $+$ \\
					CiSSA          & $+$                     & $+$                        & $\to$                       & $-$   & $-$ & $+$ \\
					CiSSA extended & $+$                     & $+$                        & $\to$                       & $\to$ & $-$ & $+$ \\
					\hline
				\end{tabular}
			}
			\end{center}
			\caption{Преимущества и недостатки методов $\SSA$, $\CISSA$} 
			\label{tab:advantages_ssa_cissa}
		\end{table}
		
		\begin{table}[H]
			\centering
			\begin{center}
				\resizebox{0.95\textwidth}{!}{ % Масштабируем таблицу
				\begin{tabular}{l|cccccccc}
					\hline
					Метод/Условие  & cos,                 & cos,                  & $\TS_{\mathrm{np1}}$   & $\TS_{\mathrm{np}}$ & group\\ 
					& $Nw \in \mathbb N$ & $Nw \not \in \mathbb N$ \\
					\hline
					Fourier                           & $+$                        & $\to$                       & $-$   & $-$ & $+$ \\
					Fourier extended                         & $+$                        & $\to$                       & $\to$   & $-$ & $+$ \\
					\hline
				\end{tabular}
			}
			\end{center}
			\caption{Преимущества и недостатки методов Fourier} 
			\label{tab:advantages_fourier}
		\end{table}
	\end{frame}
	
	
	\begin{frame}{Сравнение SSA, Фурье, CiSSA. Выводы 2}
		По полученным результатам, можно следующие выводы: 
		\begin{enumerate}
			\item Алгоритм $\CISSA$ работает лучше разложения Фурье;
			\item Если понятно, что ряд состоит только из периодических компонент, стоит использовать $\CISSA$ без процедуры расширения, поскольку она делает ошибки разделений периодики больше. И напротив, если есть непериодичность, лучше расширять ряд;
			\item Если данные зашумлены или имеется непериодичность, алгоритм $\SSA$ с улучшением разделимости справляется в среднеквадратичном лучше $\CISSA$ с расширением ряда или без. 
		\end{enumerate}
	\end{frame}
	
	
	
	
	
%	\begin{frame}{Сравнение алгоритмов. Пример 1 }
%		$\TS = \TS_{\sin} + \TS_{\cos} = \sin{\frac{2\pi}{12}x} + \frac{1}{2}\cos{\frac{2\pi}{3}x}$, $L = 96$, $N = 96 \cdot 2$ для разложения Фурье и $N = 96 \cdot 2 - 1$ для остальных, чтобы выполнялись условия выполнения разделимости частот. Сравним результаты по среднеквадратичной ошибке:
%		
%		\begin{table}[H]
%			\centering
%			\begin{tabular}{llllllll}
%				\hline
%				Метод/Компонента & $\TS_{\sin}$ & $\TS_{\cos}$ \\ 
%				\hline
%				SSA & 6.8e-30 & 1.5e-29 \\ 
%				SSA EOSSA & 1.5e-29 & 7.5e-30 \\ 
%				Fourier & 1.7e-28 & 3.5e-28 \\ 
%				CiSSA & 1.9e-29 & 5.3e-30 \\ 
%				CiSSA extended & 2.0e-04 & 8.6e-04 \\ 
%				\hline
%			\end{tabular}
%			\caption{MSE разложений ряда $\TS = \TS_{\sin} + \TS_{\cos}$ пяти методов} 
%			\label{tab:errs_fourier_cissa_sin_cos}
%		\end{table}
%		
%		
%		\note{
%			Таблица \ref{tab:errs_fourier_cissa_sin_cos} показывает, что первые четыре разложения сделали правильное (с точностью до вычислений с помощью компьютера) разделение компонент ряда. Однако расширение в методе $\CISSA$ ухудшило разделимость периодических частей.
%		}
%		
%		
%	\end{frame}
%	
%	\begin{frame}{Сравнение алгоритмов. Пример 2 }
%	$\TS = \TS_{\sin} + \TS_{\cos} + \TS_{\mathrm{noise}} = \sin{\frac{2\pi}{12}x} + \frac{1}{2}\cos{\frac{2\pi}{3}x} + \varepsilon_n$, где $\varepsilon_n \sim \mathrm N(0, 0.1)$, $L = 96$, $N = 96 \cdot 2$ для разложения Фурье и $N = 96 \cdot 2 - 1$ для остальных.
%		
%		\begin{table}[H]
%			\centering
%			\begin{tabular}{llllllll}
%				\hline
%				Метод/Компонента & $\TS_{\sin}$ & $\TS_{\cos}$ \\ 
%				\hline
%				SSA & 2.9e-04 & 3.1e-04 \\ 
%				SSA EOSSA & 2.9e-04 & 3.1e-04 \\ 
%				Fourier & 1.0e-04 & 1.1e-04 \\ 
%				CiSSA & 1.6e-04 & 1.8e-04 \\ 
%				CiSSA extended & 6.6e-04 & 1.9e-03 \\ 
%				\hline
%			\end{tabular}
%			\caption{MSE разложений ряда $\TS = \TS_{\sin} + \TS_{\cos} +\TS_{\mathrm{noise}}$ пяти методов} 
%			\label{tab:errs_fourier_cissa_sin_cos_noised}
%		\end{table}
%		
%		
%		\note{
%			Проводилось $100$ тестов, в таблице \ref{tab:errs_fourier_cissa_sin_cos_noised} указаны средние значения ошибки для одних и тех же реализаций шума.
%			
%			Был проведен парный t-критерий для зависимых выборок с целью проверки гипотезы о равенстве средних значений ошибки для каждой компоненты, попарно для всех методов. В качестве нулевой гипотезы ($H_0$) предполагалось, что средние значения двух сравниваемых выборок равны. Критический уровень значимости был установлен на уровне $\alpha = 0.05$.
%			Результаты анализа показали, что во всех случаях $p$-значение оказались меньше 0.05, что позволяет отвергнуть нулевую гипотезу.
%		}
%		
%		
%	\end{frame}
%	
%	
%	
%	
%	
%	\begin{frame}{Сравнение алгоритмов. Пример 4 }
%		$\TS = \TS_{\sin} + \TS_{\cos} + \TS_{c} + \TS_e + \TS_{\mathrm{noise}} = \sin{\frac{2\pi}{12}x} + \frac{1}{2}\cos{\frac{2\pi}{3}x} + 1 + e^{\frac{x}{100}} +  + \varepsilon_n$, где $\varepsilon_n \sim \mathrm N(0, 0.1)$, $L = 96$, $N = 96 \cdot 2$ для разложения Фурье и $N = 96 \cdot 2 - 1$.
%		
%		\begin{table}[H]
%			\centering
%			\begin{tabular}{llllllll}
%				\hline
%				Метод/Компонента & $\TS_{\sin}$ & $\TS_{\cos}$ & $\TS_{c} + \TS_e$\\ 
%				\hline
%				SSA & 2.9e-04 & 3.6e-04 & 5.2e-03 \\ 
%				SSA EOSSA & 2.9e-04 & 3.1e-04 & 9.4e-04 \\ 
%				Fourier & 6.9e-04 & 7.2e-03 & 1.2e-01 \\ 
%				CiSSA & 1.7e-04 & 7.0e-04 & 5.5e-02 \\ 
%				CiSSA extended & 6.8e-04 & 2.1e-03 & 2.7e-03 \\ 
%				\hline
%			\end{tabular}
%			\caption{MSE разложений ряда $\TS = \TS_{\sin} + \TS_{\cos} + \TS_{c} + \TS_e+\TS_{\mathrm{noise}}$ четырех методов} 
%			\label{tab:errs_fourier_cissa_trend_noised}
%		\end{table}
%		
%		
%		\note{
%			Как видно из таблицы \ref{tab:errs_fourier_cissa_trend_noised}, разделения ухудшились, однако $\SSA$ с улучшением разделимости EOSSA отработал лучше всех. Также был проведен был проведён двухвыборочный t-критерий для зависимых выборок с целью проверки гипотезы о равенстве средних значений ошибки для каждой компоненты, попарно для всех методов. В качестве нулевой гипотезы ($H_0$) предполагалось, что средние значения двух сравниваемых выборок равны. Критический уровень значимости был установлен на уровне $\alpha = 0.05$.
%			Результаты анализа показали, что во всех случаях $p$-значение оказалось меньше 0.05, что позволяет отвергнуть нулевую гипотезу.
%		}
%		
%		
%	\end{frame}
%	
%	\begin{frame}{Сравнение алгоритмов. Собственные пространства }
%		Каждый алгоритм после группировки порождает построенными матрицами собственные подпространства. В случае базового $\SSA$ алгоритма базис подпространств является адаптивным, то есть зависящим от $\TS, L, N$. Таким образом, $\SSA$ может отличить, например, произведение полиномов, экспонент и косинусов друг от друга.
%		
%		В случае $\CISSA$ базис зависит только от $L, N$. Если зафиксировать данные параметры, и менять $\TS$, базис никак не поменяется.
%		
%		
%		\note{
%			От собственных подпространств зависит то, какие компоненты временного ряда будут разделимы между собой. Это особенно важно, так как правильный выбор и адаптивность базиса определяют точность разделения сигналов и шумов в ряде. В $\SSA$ адаптивный базис позволяет эффективно выделять разнородные компоненты, такие как тренды, колебательные и стохастические элементы, даже если они сложно различимы. В то же время в $\CISSA$ базис остаётся фиксированным, что может упрощать анализ при постоянных параметрах.
%		}
%		
%		
%	\end{frame}
%	
%	
%	\begin{frame}{Сравнение алгоритмов. Реальные данные}
%		Теперь рассмотрим реальные данные --- месячные ряды промышленного производства (Industrial Production, IP), index $2010 = 100$, в США.
%		Размер выборки составляет $N = 537$. Применим как $\CISSA$, так и $\SSA$ с автоматическим определением частот и улучшением разделимости по следующим группам:
%		\begin{enumerate}
%			\item Трендовой составляющей должны отвечать низкие частоты, поэтому диапазон: $\left[0, \frac{1}{192}\right]$;
%			\item Циклы бизнеса по диапазонам: $\left[\frac{2}{192}, \frac{10}{192}\right]$;
%			\item Сезонность по частотам $\omega_k = 1/12, 1/6, 1/4, 1/3, 5/12, 1/2$;
%		\end{enumerate}
%		На основе предыдущих требований взято $L = 192$.
%		
%		\note{
%			Данные промышленного производства полезны, поскольку оно указывается в определении рецессии Национальным бюро экономических исследований (NBER), как один из четырех ежемесячных рядов индикаторов, которые необходимо проверять при анализе делового цикла. Эти показатели демонстрируют различные тенденции, сезонность и цикличность (периодические компоненты, которые соответствуют циклам бизнеса). Эти диапазононы частот возникли не случайно. Тренд ассоциируется с частотами, близкими к нулю, что позволяет отразить постоянные изменения с низкой частотой. Циклические компоненты (цикл бизнеса) --- это частоты, связанные с деловым циклом, характеризуют циклические колебания, которые, как правило, находятся в диапазоне от полутора до восьми лет. Сезонные компоненты связаны с регулярными колебаниями, такими как месячная или квартальная сезонность. 
%		}
%		
%		
%	\end{frame}
%	
%	\begin{frame}{Сравнение алгоритмов. Реальные данные}
%		\begin{figure}[H]
%			\centering
%			\includegraphics[width=1\textwidth]{img/trend inseparability example/IP_trend.png}
%			\caption{Трендовая составляющая данных IP USA}
%			\label{fig:IP_trend}
%		\end{figure}
%		
%		\note{
%			При применении FOSSA улучшения разделимости алгоритм $\SSA$ выделяет тренд довольно похоже с $\CISSA$. Весь график $\SSA$ тренд EOSSA выглядит более изогнутым при визуальном сравнении с остальными.
%		}
%		
%		
%	\end{frame}
%	
%	\begin{frame}{Сравнение алгоритмов. Реальные данные}
%		\begin{figure}[H]
%			\centering
%			\includegraphics[width=1\textwidth]{img/trend inseparability example/IP_cycle.png}
%			\caption{Циклическая составляющая данных IP USA}
%			\label{fig:IP_cycle}
%		\end{figure}
%		
%		\note{
%			Аналогичная тренду ситуация происходит с цикличностью. В случае EOSSA правый хвост (значения ряда после 2010-ого года) смешался между цикличностью и трендом.
%		}
%		
%		
%	\end{frame}
%	
%	
%	\begin{frame}{Сравнение алгоритмов. Реальные данные}
%		\begin{figure}[H]
%			\centering
%			\includegraphics[width=0.8\textwidth]{img/trend inseparability example/IP_sesonal.jpg}
%			\caption{Сезонная составляющая данных IP USA}
%			\label{fig:IP_sesonal}
%		\end{figure}
%		
%		\note{
%			Поскольку в базовом $\SSA$ адаптивный базис, сезонность является менее систематичной, разброс значений выше по сравнению с $\CISSA$.
%			
%			Таким образом, получились довольно похожие результаты в выделении тренда и цикличности при использовании $\SSA$ с FOSSA и $\CISSA$. Несколько иные результаты при $\SSA$ с EOSSA. Сезонная составляющая в силу неадаптивного базиса более строго выглядит для метода $\CISSA$.
%		}
%		
%		
%	\end{frame}
	
	
%	\begin{frame}{Дальнейшие действия}
%		
%	\end{frame}
	
	
	
	
	\begin{frame}{Список литературы}
		\small
		\bibliographystyle{plain}
		\bibliography{ref}
		
		\note{
			На данном слайде представлен список основных источников, используемых в моей работе.
			Спасибо за внимание.
		}
	\end{frame}
	
\end{document}
